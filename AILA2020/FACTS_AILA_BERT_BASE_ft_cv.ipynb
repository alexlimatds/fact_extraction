{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "previous-canvas",
   "metadata": {},
   "source": [
    "# Facts extraction with AILA data and BERT base\n",
    "### PyTorch version\n",
    "\n",
    "The model is trained trough a fune-tuning process.\n",
    "\n",
    "The model is evaluated through a cross-validation.\n",
    "\n",
    "We use the train dataset from AILA 2020. This can be obtained at https://github.com/Law-AI/semantic-segmentation;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-productivity",
   "metadata": {},
   "source": [
    "### Notebook parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adjustable-patrol",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'bert-base-uncased'\n",
    "model_reference = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-coalition",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baking-happiness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "formal-apple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.8/site-packages (4.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.11.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2021.3.17)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.8/site-packages (from transformers) (0.0.35)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.53.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.19.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "solar-pressure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.17.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "linear-english",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0a0+df837d0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "atmospheric-participation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "great-middle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.19.2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-patrick",
   "metadata": {},
   "source": [
    "### Random numbers' seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "conventional-preference",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-bahamas",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "spare-fusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 50\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "train_dir = 'train/'\n",
    "\n",
    "def read_docs(dir_name):\n",
    "  \"\"\"\n",
    "  Read the docs in a directory.\n",
    "  Params:\n",
    "    dir_name : the directory that contains the documents.\n",
    "  Returns:\n",
    "    A dictionary whose keys are the names of the read files and the values are \n",
    "    pandas dataframes. Each dataframe has sentence and label columns.\n",
    "  \"\"\"\n",
    "  docs = {} # key: file name, value: dataframe with sentences and labels\n",
    "  for f in listdir(dir_name):\n",
    "    df = pd.read_csv(\n",
    "        dir_name + f, \n",
    "        sep='\\t', \n",
    "        quoting=csv.QUOTE_NONE, \n",
    "        names=['sentence', 'label'])\n",
    "    docs[f] = df\n",
    "  return docs\n",
    "\n",
    "docs_dic = read_docs(train_dir)\n",
    "\n",
    "print('Number of documents:', len(docs_dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "lightweight-likelihood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "\tTrain files: ['d_44.txt', 'd_39.txt', 'd_12.txt', 'd_2.txt', 'd_7.txt', 'd_33.txt', 'd_16.txt', 'd_8.txt', 'd_42.txt', 'd_34.txt', 'd_40.txt', 'd_24.txt', 'd_36.txt', 'd_11.txt', 'd_13.txt', 'd_19.txt', 'd_18.txt', 'd_4.txt', 'd_1.txt', 'd_21.txt', 'd_15.txt', 'd_23.txt', 'd_32.txt', 'd_9.txt', 'd_5.txt', 'd_3.txt', 'd_26.txt', 'd_20.txt', 'd_30.txt', 'd_41.txt', 'd_46.txt', 'd_43.txt', 'd_50.txt', 'd_27.txt', 'd_25.txt', 'd_35.txt', 'd_45.txt', 'd_17.txt', 'd_48.txt', 'd_6.txt']\n",
      "\tTest files: ['d_22.txt', 'd_31.txt', 'd_49.txt', 'd_14.txt', 'd_29.txt', 'd_47.txt', 'd_10.txt', 'd_38.txt', 'd_28.txt', 'd_37.txt']\n",
      "Fold 1:\n",
      "\tTrain files: ['d_22.txt', 'd_31.txt', 'd_49.txt', 'd_14.txt', 'd_29.txt', 'd_47.txt', 'd_10.txt', 'd_38.txt', 'd_28.txt', 'd_37.txt', 'd_40.txt', 'd_24.txt', 'd_36.txt', 'd_11.txt', 'd_13.txt', 'd_19.txt', 'd_18.txt', 'd_4.txt', 'd_1.txt', 'd_21.txt', 'd_15.txt', 'd_23.txt', 'd_32.txt', 'd_9.txt', 'd_5.txt', 'd_3.txt', 'd_26.txt', 'd_20.txt', 'd_30.txt', 'd_41.txt', 'd_46.txt', 'd_43.txt', 'd_50.txt', 'd_27.txt', 'd_25.txt', 'd_35.txt', 'd_45.txt', 'd_17.txt', 'd_48.txt', 'd_6.txt']\n",
      "\tTest files: ['d_44.txt', 'd_39.txt', 'd_12.txt', 'd_2.txt', 'd_7.txt', 'd_33.txt', 'd_16.txt', 'd_8.txt', 'd_42.txt', 'd_34.txt']\n",
      "Fold 2:\n",
      "\tTrain files: ['d_22.txt', 'd_31.txt', 'd_49.txt', 'd_14.txt', 'd_29.txt', 'd_47.txt', 'd_10.txt', 'd_38.txt', 'd_28.txt', 'd_37.txt', 'd_44.txt', 'd_39.txt', 'd_12.txt', 'd_2.txt', 'd_7.txt', 'd_33.txt', 'd_16.txt', 'd_8.txt', 'd_42.txt', 'd_34.txt', 'd_15.txt', 'd_23.txt', 'd_32.txt', 'd_9.txt', 'd_5.txt', 'd_3.txt', 'd_26.txt', 'd_20.txt', 'd_30.txt', 'd_41.txt', 'd_46.txt', 'd_43.txt', 'd_50.txt', 'd_27.txt', 'd_25.txt', 'd_35.txt', 'd_45.txt', 'd_17.txt', 'd_48.txt', 'd_6.txt']\n",
      "\tTest files: ['d_40.txt', 'd_24.txt', 'd_36.txt', 'd_11.txt', 'd_13.txt', 'd_19.txt', 'd_18.txt', 'd_4.txt', 'd_1.txt', 'd_21.txt']\n",
      "Fold 3:\n",
      "\tTrain files: ['d_22.txt', 'd_31.txt', 'd_49.txt', 'd_14.txt', 'd_29.txt', 'd_47.txt', 'd_10.txt', 'd_38.txt', 'd_28.txt', 'd_37.txt', 'd_44.txt', 'd_39.txt', 'd_12.txt', 'd_2.txt', 'd_7.txt', 'd_33.txt', 'd_16.txt', 'd_8.txt', 'd_42.txt', 'd_34.txt', 'd_40.txt', 'd_24.txt', 'd_36.txt', 'd_11.txt', 'd_13.txt', 'd_19.txt', 'd_18.txt', 'd_4.txt', 'd_1.txt', 'd_21.txt', 'd_46.txt', 'd_43.txt', 'd_50.txt', 'd_27.txt', 'd_25.txt', 'd_35.txt', 'd_45.txt', 'd_17.txt', 'd_48.txt', 'd_6.txt']\n",
      "\tTest files: ['d_15.txt', 'd_23.txt', 'd_32.txt', 'd_9.txt', 'd_5.txt', 'd_3.txt', 'd_26.txt', 'd_20.txt', 'd_30.txt', 'd_41.txt']\n",
      "Fold 4:\n",
      "\tTrain files: ['d_22.txt', 'd_31.txt', 'd_49.txt', 'd_14.txt', 'd_29.txt', 'd_47.txt', 'd_10.txt', 'd_38.txt', 'd_28.txt', 'd_37.txt', 'd_44.txt', 'd_39.txt', 'd_12.txt', 'd_2.txt', 'd_7.txt', 'd_33.txt', 'd_16.txt', 'd_8.txt', 'd_42.txt', 'd_34.txt', 'd_40.txt', 'd_24.txt', 'd_36.txt', 'd_11.txt', 'd_13.txt', 'd_19.txt', 'd_18.txt', 'd_4.txt', 'd_1.txt', 'd_21.txt', 'd_15.txt', 'd_23.txt', 'd_32.txt', 'd_9.txt', 'd_5.txt', 'd_3.txt', 'd_26.txt', 'd_20.txt', 'd_30.txt', 'd_41.txt']\n",
      "\tTest files: ['d_46.txt', 'd_43.txt', 'd_50.txt', 'd_27.txt', 'd_25.txt', 'd_35.txt', 'd_45.txt', 'd_17.txt', 'd_48.txt', 'd_6.txt']\n"
     ]
    }
   ],
   "source": [
    "df_folds = pd.read_csv(\n",
    "  'train_docs_by_fold.csv', \n",
    "  sep=';', \n",
    "  names=['fold id', 'train', 'test'], \n",
    "  header=0\n",
    ")\n",
    "\n",
    "train_files_by_fold = {}\n",
    "test_files_by_fold = {}\n",
    "fold_ids = []\n",
    "\n",
    "for _, row in df_folds.iterrows():\n",
    "  fold_id = int(row['fold id'])\n",
    "  fold_ids.append(int(fold_id))\n",
    "  train_files_by_fold[fold_id] = row['train'].split(',')\n",
    "  test_files_by_fold[fold_id] = row['test'].split(',')\n",
    "  print(f'Fold {fold_id}:\\n\\tTrain files: {train_files_by_fold[fold_id]}\\n\\tTest files: {test_files_by_fold[fold_id]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-liverpool",
   "metadata": {},
   "source": [
    "### Tokenizer and Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "partial-writer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a08c167331a4e9fa14cb728e1ac4ca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=28.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e886fa2b0d4fbcbf1978a4a6ac7994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=570.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d3d33691f24172bd1908f115d28c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=231508.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed176a071f6428689d904365bf8c50c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=466062.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "growing-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "labels_to_idx = {\n",
    "  'Facts' : 0, \n",
    "  'Other' : 1\n",
    "}\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "  def __init__(self, sentences, labels, tokenizer):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "      sentences : list of strings.\n",
    "      lables : list of strings.\n",
    "    \"\"\"\n",
    "    self.len = len(sentences)\n",
    "    self.labels = list(labels)\n",
    "    self.targets = []\n",
    "    for l in labels:\n",
    "      self.targets.append(labels_to_idx[l])\n",
    "    self.targets = torch.tensor(self.targets, dtype=torch.long)\n",
    "    self.data = tokenizer(\n",
    "      sentences, \n",
    "      None,\n",
    "      add_special_tokens=True,\n",
    "      padding='longest', \n",
    "      return_token_type_ids=True, \n",
    "      return_attention_mask=True, \n",
    "      truncation=True, \n",
    "      return_tensors='pt'\n",
    "    )\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return {\n",
    "      'ids': self.data['input_ids'][index],\n",
    "      'mask': self.data['attention_mask'][index], \n",
    "      'token_type_ids': self.data['token_type_ids'][index], \n",
    "      'targets': self.targets[index], \n",
    "      'labels': self.labels[index]\n",
    "    }\n",
    "  \n",
    "  def __len__(self):\n",
    "    return self.len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sonic-press",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(docs_list):\n",
    "  sentences = []\n",
    "  labels = []\n",
    "  for doc_id in docs_list:\n",
    "    sentences.extend(docs_dic[doc_id]['sentence'].to_list())\n",
    "    labels.extend(docs_dic[doc_id]['label'].to_list())\n",
    "  #return MyDataset(sentences[:10], labels[:10], tokenizer) # for code validation\n",
    "  return MyDataset(sentences, labels, tokenizer)\n",
    "\n",
    "def count_labels(set_title, ds):\n",
    "  print(f'{set_title} numbers:')\n",
    "  print(f' Total number of sentences: {ds.len}')\n",
    "  n_facts = len([l for l in ds.labels if l == \"Facts\"])\n",
    "  print(f' Number of Facts labels: {n_facts}')\n",
    "  n_other = len([l for l in ds.labels if l == \"Other\"])\n",
    "  print(f' Number of Other labels: {n_other}')\n",
    "  return n_facts, n_other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-billy",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "automatic-decision",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceClassifier(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SentenceClassifier, self).__init__()\n",
    "    self.bert = transformers.AutoModel.from_pretrained(model_id)\n",
    "    self.dropout = torch.nn.Dropout(0.4)\n",
    "    self.classifier = torch.nn.Linear(768, 2) # 768 => hidden vector's dimension, 2 => two classes\n",
    "    torch.nn.init.xavier_uniform_(self.classifier.weight)\n",
    "\n",
    "  def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "    output_1 = self.bert(\n",
    "      input_ids=input_ids,            # input_ids.shape: (batch_size, seq_len)\n",
    "      attention_mask=attention_mask,  # attention_mask.shape: (batch_size, seq_len)\n",
    "      token_type_ids=token_type_ids   # token_type_ids.shape: (batch_size, seq_len)\n",
    "    )\n",
    "    hidden_state = output_1.last_hidden_state # hidden states of last BERT's layer => shape: (batch_size, seq_len, embedd_dim)\n",
    "    cls_embeddings = hidden_state[:, 0]       # hidden states of the CLS tokens => shape: (batch_size, embedd_dim)\n",
    "    cls_embeddings = self.dropout(cls_embeddings)\n",
    "    logits = self.classifier(cls_embeddings)  # shape: (batch_size, 2)\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-tiger",
   "metadata": {},
   "source": [
    "### Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "informative-tucson",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate(model, test_dataloader, loss_function):\n",
    "  predictions = torch.tensor([]).to(device)\n",
    "  y_true = torch.tensor([]).to(device)\n",
    "  eval_loss = 0\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    for data in tqdm(test_dataloader, desc='Evaluation'):\n",
    "      ids = data['ids'].to(device)\n",
    "      mask = data['mask'].to(device)\n",
    "      token_type_ids = data['token_type_ids'].to(device)\n",
    "      y_true_batch = data['targets'].to(device)\n",
    "      y_hat = model.forward(ids, mask, token_type_ids)\n",
    "      loss = loss_function(y_hat, y_true_batch)\n",
    "      eval_loss += loss.item()\n",
    "      predictions_batch = y_hat.argmax(dim=1)\n",
    "      predictions = torch.cat((predictions, predictions_batch))\n",
    "      y_true = torch.cat((y_true, y_true_batch))\n",
    "    predictions = predictions.detach().to('cpu').numpy()\n",
    "    y_true = y_true.detach().to('cpu').numpy()\n",
    "  eval_loss = eval_loss / len(test_dataloader)\n",
    "  # Precision, Recall, F1\n",
    "  t_metrics = precision_recall_fscore_support(\n",
    "    y_true, \n",
    "    predictions, \n",
    "    average='binary', \n",
    "    pos_label=labels_to_idx['Facts'], \n",
    "    zero_division=0)\n",
    "  \n",
    "  return eval_loss, t_metrics[0], t_metrics[1], t_metrics[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-hearing",
   "metadata": {},
   "source": [
    "### Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "interpreted-anniversary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time\n",
    "\n",
    "supports_by_fold = {}\n",
    "\n",
    "def train(fold_id, learning_rate, weight_decay, n_epochs, batch_size):\n",
    "  ds_train = get_dataset(train_files_by_fold[fold_id])\n",
    "  ds_test = get_dataset(test_files_by_fold[fold_id])\n",
    "  n_facts_train, n_other_train = count_labels('Train dataset', ds_train)\n",
    "  n_facts_test, n_other_test = count_labels('Test dataset', ds_test)\n",
    "  supports_by_fold[fold_id] = {\n",
    "    'facts_train' : n_facts_train, \n",
    "    'other_train' : n_other_train, \n",
    "    'facts_test' : n_facts_test, \n",
    "    'other_test' : n_other_test\n",
    "  }\n",
    "  dl_train = torch.utils.data.DataLoader(ds_train, batch_size=batch_size, shuffle=True)\n",
    "  dl_test = torch.utils.data.DataLoader(ds_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "  sentence_classifier = SentenceClassifier().to(device)\n",
    "  criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "  optimizer = torch.optim.Adam(\n",
    "    sentence_classifier.parameters(), \n",
    "    lr=learning_rate, \n",
    "    betas=(0.9, 0.999), \n",
    "    eps=1e-8, \n",
    "    weight_decay=weight_decay\n",
    "  )\n",
    "  lr_scheduler = transformers.get_linear_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps = 0, \n",
    "    num_training_steps = len(dl_train) * n_epochs\n",
    "  )\n",
    "  \n",
    "  metrics = {} # key: epoch number, value: numpy tensor storing train loss, test loss, Precision, Recall, F1\n",
    "  for epoch in range(1, n_epochs + 1):\n",
    "    epoch_loss = 0\n",
    "    sentence_classifier.train()\n",
    "    for train_data in tqdm(dl_train, desc=f'Epoch {epoch} (train)'):\n",
    "      optimizer.zero_grad()\n",
    "      ids = train_data['ids'].to(device)\n",
    "      mask = train_data['mask'].to(device)\n",
    "      token_type_ids = train_data['token_type_ids'].to(device)\n",
    "      y_hat = sentence_classifier(ids, mask, token_type_ids)\n",
    "      y_true = train_data['targets'].to(device)\n",
    "      loss = criterion(y_hat, y_true)\n",
    "      epoch_loss += loss.item()\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(sentence_classifier.parameters(), 1.0)\n",
    "      optimizer.step()\n",
    "      lr_scheduler.step()\n",
    "    epoch_loss = epoch_loss / len(dl_train)\n",
    "    # evaluation\n",
    "    optimizer.zero_grad()\n",
    "    eval_loss, p, r, f1 = evaluate(sentence_classifier, dl_test, criterion)\n",
    "    #storing metrics\n",
    "    metrics[epoch] = np.array([epoch_loss, eval_loss, p, r, f1])\n",
    "    print(f'=> Epoch {epoch}')\n",
    "    print(f'  Train loss: {epoch_loss:.6f}')\n",
    "    print(f'  Test loss:  {eval_loss:.6f}')\n",
    "    print(f'  Precision:  {p:.6f}')\n",
    "    print(f'  Recall:     {r:.6f}')\n",
    "    print(f'  F1:         {f1:.6f}')\n",
    "    time.sleep(0.5) # in order to don't mess the progress bars\n",
    "  \n",
    "  return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "civic-letters",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************\n",
      "               FOLD 0\n",
      "********************************************\n",
      "Train dataset numbers:\n",
      " Total number of sentences: 7693\n",
      " Number of Facts labels: 1584\n",
      " Number of Other labels: 6109\n",
      "Test dataset numbers:\n",
      " Total number of sentences: 1687\n",
      " Number of Facts labels: 635\n",
      " Number of Other labels: 1052\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39cec86d75af4744914d19e2930342d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=440473133.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Epoch 1 (train): 100%|██████████| 241/241 [03:19<00:00,  1.21it/s]\n",
      "Evaluation: 100%|██████████| 53/53 [00:12<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 1\n",
      "  Train loss: 0.387629\n",
      "  Test loss:  0.699228\n",
      "  Precision:  0.785714\n",
      "  Recall:     0.242520\n",
      "  F1:         0.370638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 (train): 100%|██████████| 241/241 [03:20<00:00,  1.20it/s]\n",
      "Evaluation: 100%|██████████| 53/53 [00:12<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 2\n",
      "  Train loss: 0.296258\n",
      "  Test loss:  0.524545\n",
      "  Precision:  0.680887\n",
      "  Recall:     0.628346\n",
      "  F1:         0.653563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 (train): 100%|██████████| 241/241 [03:20<00:00,  1.20it/s]\n",
      "Evaluation: 100%|██████████| 53/53 [00:12<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 3\n",
      "  Train loss: 0.225072\n",
      "  Test loss:  0.582935\n",
      "  Precision:  0.695341\n",
      "  Recall:     0.611024\n",
      "  F1:         0.650461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 (train): 100%|██████████| 241/241 [03:20<00:00,  1.20it/s]\n",
      "Evaluation: 100%|██████████| 53/53 [00:12<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 4\n",
      "  Train loss: 0.165317\n",
      "  Test loss:  0.716601\n",
      "  Precision:  0.679577\n",
      "  Recall:     0.607874\n",
      "  F1:         0.641729\n",
      "********************************************\n",
      "               FOLD 1\n",
      "********************************************\n",
      "Train dataset numbers:\n",
      " Total number of sentences: 7782\n",
      " Number of Facts labels: 1772\n",
      " Number of Other labels: 6010\n",
      "Test dataset numbers:\n",
      " Total number of sentences: 1598\n",
      " Number of Facts labels: 447\n",
      " Number of Other labels: 1151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Epoch 1 (train): 100%|██████████| 244/244 [02:48<00:00,  1.45it/s]\n",
      "Evaluation: 100%|██████████| 50/50 [00:14<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 1\n",
      "  Train loss: 0.415771\n",
      "  Test loss:  0.620260\n",
      "  Precision:  0.777251\n",
      "  Recall:     0.366890\n",
      "  F1:         0.498480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 (train): 100%|██████████| 244/244 [02:48<00:00,  1.45it/s]\n",
      "Evaluation: 100%|██████████| 50/50 [00:14<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 2\n",
      "  Train loss: 0.316106\n",
      "  Test loss:  0.527135\n",
      "  Precision:  0.733333\n",
      "  Recall:     0.467562\n",
      "  F1:         0.571038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 (train): 100%|██████████| 244/244 [02:48<00:00,  1.45it/s]\n",
      "Evaluation: 100%|██████████| 50/50 [00:14<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 3\n",
      "  Train loss: 0.246658\n",
      "  Test loss:  0.678702\n",
      "  Precision:  0.733096\n",
      "  Recall:     0.460850\n",
      "  F1:         0.565934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 (train): 100%|██████████| 244/244 [02:48<00:00,  1.45it/s]\n",
      "Evaluation: 100%|██████████| 50/50 [00:14<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 4\n",
      "  Train loss: 0.185551\n",
      "  Test loss:  0.739161\n",
      "  Precision:  0.707483\n",
      "  Recall:     0.465324\n",
      "  F1:         0.561404\n",
      "********************************************\n",
      "               FOLD 2\n",
      "********************************************\n",
      "Train dataset numbers:\n",
      " Total number of sentences: 7002\n",
      " Number of Facts labels: 1844\n",
      " Number of Other labels: 5158\n",
      "Test dataset numbers:\n",
      " Total number of sentences: 2378\n",
      " Number of Facts labels: 375\n",
      " Number of Other labels: 2003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Epoch 1 (train): 100%|██████████| 219/219 [03:01<00:00,  1.20it/s]\n",
      "Evaluation: 100%|██████████| 75/75 [00:16<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 1\n",
      "  Train loss: 0.444184\n",
      "  Test loss:  0.311678\n",
      "  Precision:  0.569014\n",
      "  Recall:     0.538667\n",
      "  F1:         0.553425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 (train): 100%|██████████| 219/219 [03:01<00:00,  1.20it/s]\n",
      "Evaluation: 100%|██████████| 75/75 [00:16<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 2\n",
      "  Train loss: 0.349405\n",
      "  Test loss:  0.321117\n",
      "  Precision:  0.585139\n",
      "  Recall:     0.504000\n",
      "  F1:         0.541547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 (train): 100%|██████████| 219/219 [03:01<00:00,  1.20it/s]\n",
      "Evaluation: 100%|██████████| 75/75 [00:16<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 3\n",
      "  Train loss: 0.269186\n",
      "  Test loss:  0.358549\n",
      "  Precision:  0.555263\n",
      "  Recall:     0.562667\n",
      "  F1:         0.558940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 (train): 100%|██████████| 219/219 [03:01<00:00,  1.20it/s]\n",
      "Evaluation: 100%|██████████| 75/75 [00:16<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 4\n",
      "  Train loss: 0.211970\n",
      "  Test loss:  0.412257\n",
      "  Precision:  0.547264\n",
      "  Recall:     0.586667\n",
      "  F1:         0.566281\n",
      "********************************************\n",
      "               FOLD 3\n",
      "********************************************\n",
      "Train dataset numbers:\n",
      " Total number of sentences: 7581\n",
      " Number of Facts labels: 1863\n",
      " Number of Other labels: 5718\n",
      "Test dataset numbers:\n",
      " Total number of sentences: 1799\n",
      " Number of Facts labels: 356\n",
      " Number of Other labels: 1443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Epoch 1 (train): 100%|██████████| 237/237 [03:16<00:00,  1.21it/s]\n",
      "Evaluation: 100%|██████████| 57/57 [00:12<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 1\n",
      "  Train loss: 0.438794\n",
      "  Test loss:  0.361082\n",
      "  Precision:  0.599237\n",
      "  Recall:     0.441011\n",
      "  F1:         0.508091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 (train): 100%|██████████| 237/237 [03:16<00:00,  1.21it/s]\n",
      "Evaluation: 100%|██████████| 57/57 [00:12<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 2\n",
      "  Train loss: 0.340290\n",
      "  Test loss:  0.434822\n",
      "  Precision:  0.495050\n",
      "  Recall:     0.702247\n",
      "  F1:         0.580720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 (train): 100%|██████████| 237/237 [03:16<00:00,  1.21it/s]\n",
      "Evaluation: 100%|██████████| 57/57 [00:12<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 3\n",
      "  Train loss: 0.265857\n",
      "  Test loss:  0.444611\n",
      "  Precision:  0.505133\n",
      "  Recall:     0.691011\n",
      "  F1:         0.583630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 (train): 100%|██████████| 237/237 [03:17<00:00,  1.20it/s]\n",
      "Evaluation: 100%|██████████| 57/57 [00:12<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 4\n",
      "  Train loss: 0.204443\n",
      "  Test loss:  0.522898\n",
      "  Precision:  0.488798\n",
      "  Recall:     0.674157\n",
      "  F1:         0.566706\n",
      "********************************************\n",
      "               FOLD 4\n",
      "********************************************\n",
      "Train dataset numbers:\n",
      " Total number of sentences: 7462\n",
      " Number of Facts labels: 1813\n",
      " Number of Other labels: 5649\n",
      "Test dataset numbers:\n",
      " Total number of sentences: 1918\n",
      " Number of Facts labels: 406\n",
      " Number of Other labels: 1512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Epoch 1 (train): 100%|██████████| 234/234 [03:13<00:00,  1.21it/s]\n",
      "Evaluation: 100%|██████████| 60/60 [00:10<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 1\n",
      "  Train loss: 0.438497\n",
      "  Test loss:  0.329522\n",
      "  Precision:  0.644444\n",
      "  Recall:     0.571429\n",
      "  F1:         0.605744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 (train): 100%|██████████| 234/234 [03:13<00:00,  1.21it/s]\n",
      "Evaluation: 100%|██████████| 60/60 [00:10<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 2\n",
      "  Train loss: 0.341289\n",
      "  Test loss:  0.353321\n",
      "  Precision:  0.571121\n",
      "  Recall:     0.652709\n",
      "  F1:         0.609195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 (train): 100%|██████████| 234/234 [03:13<00:00,  1.21it/s]\n",
      "Evaluation: 100%|██████████| 60/60 [00:10<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 3\n",
      "  Train loss: 0.268290\n",
      "  Test loss:  0.375416\n",
      "  Precision:  0.574074\n",
      "  Recall:     0.687192\n",
      "  F1:         0.625561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 (train): 100%|██████████| 234/234 [03:13<00:00,  1.21it/s]\n",
      "Evaluation: 100%|██████████| 60/60 [00:10<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 4\n",
      "  Train loss: 0.207038\n",
      "  Test loss:  0.427290\n",
      "  Precision:  0.574786\n",
      "  Recall:     0.662562\n",
      "  F1:         0.615561\n",
      "CPU times: user 50min 46s, sys: 16min 45s, total: 1h 7min 32s\n",
      "Wall time: 1h 7min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training params\n",
    "n_epochs = 4\n",
    "learning_rate = 2e-5\n",
    "weight_decay = 1e-3\n",
    "batch_size = 32\n",
    "\n",
    "#fold_ids = [0, 1] # for code validation\n",
    "raw_metrics = {} # key: epoch, value: numpy tensor of shape (n_folds, 5)\n",
    "for fold_id in fold_ids:\n",
    "  print('********************************************')\n",
    "  print(f'               FOLD {fold_id}')\n",
    "  print('********************************************')\n",
    "  fold_metrics = train(fold_id, learning_rate, weight_decay, n_epochs, batch_size)\n",
    "  for epoch, scores in fold_metrics.items():\n",
    "    epoch_metrics = raw_metrics.get(epoch, None)\n",
    "    if epoch_metrics is None:\n",
    "      raw_metrics[epoch] = scores\n",
    "    else:\n",
    "      raw_metrics[epoch] = np.vstack((epoch_metrics, scores))\n",
    "\n",
    "metrics = pd.DataFrame(columns=['Epoch', 'Train loss', 'std', 'Test loss', 'std', 'Precision', 'P std', 'Recall', 'R std', 'F1', 'F1 std'])\n",
    "for i, (epoch, scores) in enumerate(raw_metrics.items()):\n",
    "  mean = np.mean(scores, axis=0)\n",
    "  std = np.std(scores, axis=0)\n",
    "  metrics.loc[i] = [\n",
    "      f'{epoch}', \n",
    "      f'{mean[0]:.6f}', f'{std[0]:.6f}',  # train loss\n",
    "      f'{mean[1]:.6f}', f'{std[1]:.6f}',  # test loss\n",
    "      f'{mean[2]:.4f}', f'{std[2]:.4f}',  # precision\n",
    "      f'{mean[3]:.4f}', f'{std[3]:.4f}',  # recall\n",
    "      f'{mean[4]:.4f}', f'{std[4]:.4f}'   # f1\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-poker",
   "metadata": {},
   "source": [
    "### Outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "progressive-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def save_report(avg_metrics, complete_metrics, dest_dir):\n",
    "  \"\"\"\n",
    "  Arguments:\n",
    "    avg_metrics : A pandas Dataframe with the averaged metrics.\n",
    "    complete_metrics : A dictionary with the metrics by epoch. The key indicates the epoch. \n",
    "              Each value must be a numpy tensor of shape (n_folds, 5).\n",
    "    dest_dir : The directory where the report will be saved.\n",
    "  \"\"\"\n",
    "  report = (\n",
    "      'RESULTS REPORT\\n'\n",
    "      'Model: Legal BERT\\n'\n",
    "      'Evaluation: cross-validation\\n'\n",
    "      'Train scheme: fine-tuning\\n'\n",
    "      f'Batch size: {batch_size}\\n'\n",
    "      f'Learning rate: {learning_rate}\\n'\n",
    "      f'Weight decay: {weight_decay}\\n\\n'\n",
    "  )\n",
    "  \n",
    "  report += 'Averages:\\n'\n",
    "  report += avg_metrics.to_string(index=False, justify='center')\n",
    "  \n",
    "  report += '\\n\\nDetailed report:\\n'\n",
    "  report += 'Supports by fold:\\n'\n",
    "  for fold_id, support in supports_by_fold.items():\n",
    "    report += f'=> Fold {fold_id}:\\n'\n",
    "    report += f'  Facts (train): {support[\"facts_train\"]}\\t\\tOther (train): {support[\"other_train\"]}\\n'\n",
    "    report += f'  Facts (test): {support[\"facts_test\"]}\\t\\tOther (test): {support[\"other_test\"]}\\n'\n",
    "  \n",
    "  report += '\\nScores:\\n'\n",
    "  for epoch, scores in complete_metrics.items():\n",
    "    df = pd.DataFrame(\n",
    "      scores, \n",
    "      columns=['Train loss', 'Test loss', 'Precision', 'Recall', 'F1'], \n",
    "      index=[f'Fold {i}' for i in range(scores.shape[0])])\n",
    "    report += f'Epoch: {epoch}\\n' + df.to_string() + '\\n\\n'\n",
    "    \n",
    "  with open(dest_dir + f'report-{model_reference}_ft_{datetime.now().strftime(\"%Y-%m-%d-%Hh%Mmin\")}.txt', 'w') as f:\n",
    "    f.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "through-deposit",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_report(metrics, raw_metrics, './')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "invalid-postage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Train loss</th>\n",
       "      <th>std</th>\n",
       "      <th>Test loss</th>\n",
       "      <th>std</th>\n",
       "      <th>Precision</th>\n",
       "      <th>P std</th>\n",
       "      <th>Recall</th>\n",
       "      <th>R std</th>\n",
       "      <th>F1</th>\n",
       "      <th>F1 std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.424975</td>\n",
       "      <td>0.021082</td>\n",
       "      <td>0.464354</td>\n",
       "      <td>0.162251</td>\n",
       "      <td>0.6751</td>\n",
       "      <td>0.0901</td>\n",
       "      <td>0.4321</td>\n",
       "      <td>0.1192</td>\n",
       "      <td>0.5073</td>\n",
       "      <td>0.0782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.328670</td>\n",
       "      <td>0.019660</td>\n",
       "      <td>0.432188</td>\n",
       "      <td>0.084980</td>\n",
       "      <td>0.6131</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.5910</td>\n",
       "      <td>0.0899</td>\n",
       "      <td>0.5912</td>\n",
       "      <td>0.0379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.255013</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.488043</td>\n",
       "      <td>0.123851</td>\n",
       "      <td>0.6126</td>\n",
       "      <td>0.0868</td>\n",
       "      <td>0.6025</td>\n",
       "      <td>0.0857</td>\n",
       "      <td>0.5969</td>\n",
       "      <td>0.0354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.194864</td>\n",
       "      <td>0.017276</td>\n",
       "      <td>0.563641</td>\n",
       "      <td>0.139551</td>\n",
       "      <td>0.5996</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>0.5993</td>\n",
       "      <td>0.0745</td>\n",
       "      <td>0.5903</td>\n",
       "      <td>0.0324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Epoch Train loss       std Test loss       std Precision   P std  Recall  \\\n",
       "0     1   0.424975  0.021082  0.464354  0.162251    0.6751  0.0901  0.4321   \n",
       "1     2   0.328670  0.019660  0.432188  0.084980    0.6131  0.0843  0.5910   \n",
       "2     3   0.255013  0.017094  0.488043  0.123851    0.6126  0.0868  0.6025   \n",
       "3     4   0.194864  0.017276  0.563641  0.139551    0.5996  0.0821  0.5993   \n",
       "\n",
       "    R std      F1  F1 std  \n",
       "0  0.1192  0.5073  0.0782  \n",
       "1  0.0899  0.5912  0.0379  \n",
       "2  0.0857  0.5969  0.0354  \n",
       "3  0.0745  0.5903  0.0324  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "metrics_display = display(metrics, display_id='metrics_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-spectrum",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
