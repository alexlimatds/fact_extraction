{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "helpful-failing",
   "metadata": {},
   "source": [
    "# Facts extraction with AILA data, BERT base and positional encoding of sentences\n",
    "### PyTorch version\n",
    "\n",
    "The model is trained trough a fune-tuning process. A feature vector is generated from the embedding vector of  CLS token and from the positional encoding (PE) of the sentence. The PE is generated in order to represent the document position occupied by a sentence.\n",
    "\n",
    "The model is evaluated through a cross-validation.\n",
    "\n",
    "We use the train dataset from AILA 2020. This can be obtained at https://github.com/Law-AI/semantic-segmentation;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-former",
   "metadata": {},
   "source": [
    "### Notebook parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hawaiian-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'bert-base-uncased'\n",
    "model_reference = 'bert-base-uncased_PE'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-shipping",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "familiar-effects",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "assigned-special",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.8/site-packages (4.17.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.8/site-packages (from transformers) (0.0.35)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.53.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2021.3.17)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.19.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.11.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "professional-steps",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.17.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "artistic-healing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0a0+df837d0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "binding-wealth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "small-dressing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.19.2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-binary",
   "metadata": {},
   "source": [
    "### Random numbers' seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "detailed-norman",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-antigua",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "promising-authority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 50\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "train_dir = 'train/'\n",
    "\n",
    "def read_docs(dir_name):\n",
    "  \"\"\"\n",
    "  Read the docs in a directory.\n",
    "  Params:\n",
    "    dir_name : the directory that contains the documents.\n",
    "  Returns:\n",
    "    A dictionary whose keys are the names of the read files and the values are \n",
    "    pandas dataframes. Each dataframe has sentence and label columns.\n",
    "  \"\"\"\n",
    "  docs = {} # key: file name, value: dataframe with sentences and labels\n",
    "  for f in listdir(dir_name):\n",
    "    df = pd.read_csv(\n",
    "        dir_name + f, \n",
    "        sep='\\t', \n",
    "        quoting=csv.QUOTE_NONE, \n",
    "        names=['sentence', 'label'])\n",
    "    docs[f] = df\n",
    "  return docs\n",
    "\n",
    "docs_dic = read_docs(train_dir)\n",
    "\n",
    "print('Number of documents:', len(docs_dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "another-latin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "\tTrain files: ['d_44.txt', 'd_39.txt', 'd_12.txt', 'd_2.txt', 'd_7.txt', 'd_33.txt', 'd_16.txt', 'd_8.txt', 'd_42.txt', 'd_34.txt', 'd_40.txt', 'd_24.txt', 'd_36.txt', 'd_11.txt', 'd_13.txt', 'd_19.txt', 'd_18.txt', 'd_4.txt', 'd_1.txt', 'd_21.txt', 'd_15.txt', 'd_23.txt', 'd_32.txt', 'd_9.txt', 'd_5.txt', 'd_3.txt', 'd_26.txt', 'd_20.txt', 'd_30.txt', 'd_41.txt', 'd_46.txt', 'd_43.txt', 'd_50.txt', 'd_27.txt', 'd_25.txt', 'd_35.txt', 'd_45.txt', 'd_17.txt', 'd_48.txt', 'd_6.txt']\n",
      "\tTest files: ['d_22.txt', 'd_31.txt', 'd_49.txt', 'd_14.txt', 'd_29.txt', 'd_47.txt', 'd_10.txt', 'd_38.txt', 'd_28.txt', 'd_37.txt']\n",
      "Fold 1:\n",
      "\tTrain files: ['d_22.txt', 'd_31.txt', 'd_49.txt', 'd_14.txt', 'd_29.txt', 'd_47.txt', 'd_10.txt', 'd_38.txt', 'd_28.txt', 'd_37.txt', 'd_40.txt', 'd_24.txt', 'd_36.txt', 'd_11.txt', 'd_13.txt', 'd_19.txt', 'd_18.txt', 'd_4.txt', 'd_1.txt', 'd_21.txt', 'd_15.txt', 'd_23.txt', 'd_32.txt', 'd_9.txt', 'd_5.txt', 'd_3.txt', 'd_26.txt', 'd_20.txt', 'd_30.txt', 'd_41.txt', 'd_46.txt', 'd_43.txt', 'd_50.txt', 'd_27.txt', 'd_25.txt', 'd_35.txt', 'd_45.txt', 'd_17.txt', 'd_48.txt', 'd_6.txt']\n",
      "\tTest files: ['d_44.txt', 'd_39.txt', 'd_12.txt', 'd_2.txt', 'd_7.txt', 'd_33.txt', 'd_16.txt', 'd_8.txt', 'd_42.txt', 'd_34.txt']\n",
      "Fold 2:\n",
      "\tTrain files: ['d_22.txt', 'd_31.txt', 'd_49.txt', 'd_14.txt', 'd_29.txt', 'd_47.txt', 'd_10.txt', 'd_38.txt', 'd_28.txt', 'd_37.txt', 'd_44.txt', 'd_39.txt', 'd_12.txt', 'd_2.txt', 'd_7.txt', 'd_33.txt', 'd_16.txt', 'd_8.txt', 'd_42.txt', 'd_34.txt', 'd_15.txt', 'd_23.txt', 'd_32.txt', 'd_9.txt', 'd_5.txt', 'd_3.txt', 'd_26.txt', 'd_20.txt', 'd_30.txt', 'd_41.txt', 'd_46.txt', 'd_43.txt', 'd_50.txt', 'd_27.txt', 'd_25.txt', 'd_35.txt', 'd_45.txt', 'd_17.txt', 'd_48.txt', 'd_6.txt']\n",
      "\tTest files: ['d_40.txt', 'd_24.txt', 'd_36.txt', 'd_11.txt', 'd_13.txt', 'd_19.txt', 'd_18.txt', 'd_4.txt', 'd_1.txt', 'd_21.txt']\n",
      "Fold 3:\n",
      "\tTrain files: ['d_22.txt', 'd_31.txt', 'd_49.txt', 'd_14.txt', 'd_29.txt', 'd_47.txt', 'd_10.txt', 'd_38.txt', 'd_28.txt', 'd_37.txt', 'd_44.txt', 'd_39.txt', 'd_12.txt', 'd_2.txt', 'd_7.txt', 'd_33.txt', 'd_16.txt', 'd_8.txt', 'd_42.txt', 'd_34.txt', 'd_40.txt', 'd_24.txt', 'd_36.txt', 'd_11.txt', 'd_13.txt', 'd_19.txt', 'd_18.txt', 'd_4.txt', 'd_1.txt', 'd_21.txt', 'd_46.txt', 'd_43.txt', 'd_50.txt', 'd_27.txt', 'd_25.txt', 'd_35.txt', 'd_45.txt', 'd_17.txt', 'd_48.txt', 'd_6.txt']\n",
      "\tTest files: ['d_15.txt', 'd_23.txt', 'd_32.txt', 'd_9.txt', 'd_5.txt', 'd_3.txt', 'd_26.txt', 'd_20.txt', 'd_30.txt', 'd_41.txt']\n",
      "Fold 4:\n",
      "\tTrain files: ['d_22.txt', 'd_31.txt', 'd_49.txt', 'd_14.txt', 'd_29.txt', 'd_47.txt', 'd_10.txt', 'd_38.txt', 'd_28.txt', 'd_37.txt', 'd_44.txt', 'd_39.txt', 'd_12.txt', 'd_2.txt', 'd_7.txt', 'd_33.txt', 'd_16.txt', 'd_8.txt', 'd_42.txt', 'd_34.txt', 'd_40.txt', 'd_24.txt', 'd_36.txt', 'd_11.txt', 'd_13.txt', 'd_19.txt', 'd_18.txt', 'd_4.txt', 'd_1.txt', 'd_21.txt', 'd_15.txt', 'd_23.txt', 'd_32.txt', 'd_9.txt', 'd_5.txt', 'd_3.txt', 'd_26.txt', 'd_20.txt', 'd_30.txt', 'd_41.txt']\n",
      "\tTest files: ['d_46.txt', 'd_43.txt', 'd_50.txt', 'd_27.txt', 'd_25.txt', 'd_35.txt', 'd_45.txt', 'd_17.txt', 'd_48.txt', 'd_6.txt']\n"
     ]
    }
   ],
   "source": [
    "df_folds = pd.read_csv(\n",
    "  'train_docs_by_fold.csv', \n",
    "  sep=';', \n",
    "  names=['fold id', 'train', 'test'], \n",
    "  header=0\n",
    ")\n",
    "\n",
    "train_files_by_fold = {}\n",
    "test_files_by_fold = {}\n",
    "fold_ids = []\n",
    "\n",
    "for _, row in df_folds.iterrows():\n",
    "  fold_id = int(row['fold id'])\n",
    "  fold_ids.append(int(fold_id))\n",
    "  train_files_by_fold[fold_id] = row['train'].split(',')\n",
    "  test_files_by_fold[fold_id] = row['test'].split(',')\n",
    "  print(f'Fold {fold_id}:\\n\\tTrain files: {train_files_by_fold[fold_id]}\\n\\tTest files: {test_files_by_fold[fold_id]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-joint",
   "metadata": {},
   "source": [
    "### Positional encodings\n",
    "Since this implementation of positional encoding computing is relatively slow, let's do it in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "statutory-glory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 31s, sys: 52.6 ms, total: 3min 31s\n",
      "Wall time: 3min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def get_PE(seq_len, d, n=10000):\n",
    "  \"\"\"\n",
    "  Returns a positional encoding matrix.\n",
    "  Code adapted from https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/\n",
    "  Arguments:\n",
    "    seq_len : the length of the sequence.\n",
    "    d : the embedding (encoding) dimension.\n",
    "  Returns:\n",
    "    A PyTorch tensor with shape (seq_len, d).\n",
    "  \"\"\"\n",
    "  P = torch.zeros((seq_len, d))\n",
    "  for k in range(seq_len):\n",
    "    for i in torch.arange(int(d/2)):\n",
    "      denominator = np.power(n, 2*i/d)\n",
    "      P[k, 2*i] = np.sin(k/denominator)\n",
    "      P[k, 2*i+1] = np.cos(k/denominator)\n",
    "  return P\n",
    "\n",
    "def get_PE_by_doc():\n",
    "  pe_dic = {}\n",
    "  for doc_id in docs_dic.keys():\n",
    "    doc_len = len(docs_dic[doc_id]['sentence'].to_list())\n",
    "    pe_dic[doc_id] = get_PE(doc_len, 768) # 768 is the BERT embedding dimension\n",
    "  return pe_dic\n",
    "\n",
    "pe_by_doc = get_PE_by_doc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-colon",
   "metadata": {},
   "source": [
    "### Tokenizer and Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "civic-colony",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "precious-catholic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "labels_to_idx = {\n",
    "  'Facts' : 0, \n",
    "  'Other' : 1\n",
    "}\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "  def __init__(self, sentences, labels, pe, tokenizer):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "      sentences : list of strings.\n",
    "      labels : list of strings.\n",
    "      pe : PyTorch tensor with the positional encoding of sentences.\n",
    "      tokenizer : an instance of transformes tokenizer.\n",
    "    \"\"\"\n",
    "    self.len = len(sentences)\n",
    "    self.labels = list(labels)\n",
    "    self.pe = pe\n",
    "    # encoding targets\n",
    "    self.targets = []\n",
    "    for l in labels:\n",
    "      self.targets.append(labels_to_idx[l])\n",
    "    self.targets = torch.tensor(self.targets, dtype=torch.long)\n",
    "    # tokenizing sentences\n",
    "    self.data = tokenizer(\n",
    "      sentences, \n",
    "      None,\n",
    "      add_special_tokens=True,\n",
    "      padding='longest', \n",
    "      return_token_type_ids=True, \n",
    "      return_attention_mask=True, \n",
    "      truncation=True, \n",
    "      return_tensors='pt'\n",
    "    )\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return {\n",
    "      'ids': self.data['input_ids'][index],\n",
    "      'mask': self.data['attention_mask'][index], \n",
    "      'token_type_ids': self.data['token_type_ids'][index], \n",
    "      'target': self.targets[index], \n",
    "      'label': self.labels[index], \n",
    "      'pe': self.pe[index]\n",
    "    }\n",
    "  \n",
    "  def __len__(self):\n",
    "    return self.len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "collected-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(docs_list):\n",
    "  sentences = []\n",
    "  labels = []\n",
    "  pe = []\n",
    "  for doc_id in docs_list:\n",
    "    doc_sentences = docs_dic[doc_id]['sentence'].to_list()\n",
    "    sentences.extend(doc_sentences)\n",
    "    labels.extend(docs_dic[doc_id]['label'].to_list())\n",
    "    pe.append(pe_by_doc[doc_id]) # 768 is the BERT embedding dimension\n",
    "  pe = torch.vstack(pe)\n",
    "  #return MyDataset(sentences[:10], labels[:10], pe, tokenizer) # for code validation\n",
    "  return MyDataset(sentences, labels, pe, tokenizer)\n",
    "\n",
    "def count_labels(set_title, ds):\n",
    "  print(f'{set_title} numbers:')\n",
    "  print(f' Total number of sentences: {ds.len}')\n",
    "  n_facts = len([l for l in ds.labels if l == \"Facts\"])\n",
    "  print(f' Number of Facts labels: {n_facts}')\n",
    "  n_other = len([l for l in ds.labels if l == \"Other\"])\n",
    "  print(f' Number of Other labels: {n_other}')\n",
    "  return n_facts, n_other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-destruction",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "sudden-fluid",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceClassifier(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SentenceClassifier, self).__init__()\n",
    "    self.bert = transformers.AutoModel.from_pretrained(model_id)\n",
    "    self.dropout = torch.nn.Dropout(0.4)\n",
    "    self.classifier = torch.nn.Linear(768, 2) # 768 => hidden vector's dimension, 2 => two classes\n",
    "    torch.nn.init.xavier_uniform_(self.classifier.weight)\n",
    "\n",
    "  def forward(self, input_ids, attention_mask, token_type_ids, pe):\n",
    "    output_1 = self.bert(\n",
    "      input_ids=input_ids,            # input_ids.shape: (batch_size, seq_len)\n",
    "      attention_mask=attention_mask,  # attention_mask.shape: (batch_size, seq_len)\n",
    "      token_type_ids=token_type_ids   # token_type_ids.shape: (batch_size, seq_len)\n",
    "    )\n",
    "    hidden_state = output_1.last_hidden_state # hidden states of last BERT's layer => shape: (batch_size, seq_len, embedd_dim)\n",
    "    cls_embeddings = hidden_state[:, 0]       # hidden states of the CLS tokens => shape: (batch_size, embedd_dim)\n",
    "    embeddings = cls_embeddings + pe\n",
    "    embeddings = self.dropout(embeddings)\n",
    "    logits = self.classifier(embeddings)  # shape: (batch_size, 2)\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-leader",
   "metadata": {},
   "source": [
    "### Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "amended-drove",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate(model, test_dataloader, loss_function):\n",
    "  predictions = torch.tensor([]).to(device)\n",
    "  y_true = torch.tensor([]).to(device)\n",
    "  eval_loss = 0\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    for data in tqdm(test_dataloader, desc='Evaluation'):\n",
    "      ids = data['ids'].to(device)\n",
    "      mask = data['mask'].to(device)\n",
    "      token_type_ids = data['token_type_ids'].to(device)\n",
    "      pe = data['pe'].to(device)\n",
    "      y_true_batch = data['target'].to(device)\n",
    "      y_hat = model.forward(ids, mask, token_type_ids, pe)\n",
    "      loss = loss_function(y_hat, y_true_batch)\n",
    "      eval_loss += loss.item()\n",
    "      predictions_batch = y_hat.argmax(dim=1)\n",
    "      predictions = torch.cat((predictions, predictions_batch))\n",
    "      y_true = torch.cat((y_true, y_true_batch))\n",
    "    predictions = predictions.detach().to('cpu').numpy()\n",
    "    y_true = y_true.detach().to('cpu').numpy()\n",
    "  eval_loss = eval_loss / len(test_dataloader)\n",
    "  # Precision, Recall, F1\n",
    "  t_metrics = precision_recall_fscore_support(\n",
    "    y_true, \n",
    "    predictions, \n",
    "    average='binary', \n",
    "    pos_label=labels_to_idx['Facts'], \n",
    "    zero_division=0)\n",
    "  \n",
    "  return eval_loss, t_metrics[0], t_metrics[1], t_metrics[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-liberia",
   "metadata": {},
   "source": [
    "### Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "painted-flash",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time\n",
    "\n",
    "supports_by_fold = {}\n",
    "\n",
    "def train(fold_id, learning_rate, weight_decay, n_epochs, batch_size):\n",
    "  ds_train = get_dataset(train_files_by_fold[fold_id])\n",
    "  ds_test = get_dataset(test_files_by_fold[fold_id])\n",
    "  n_facts_train, n_other_train = count_labels('Train dataset', ds_train)\n",
    "  n_facts_test, n_other_test = count_labels('Test dataset', ds_test)\n",
    "  supports_by_fold[fold_id] = {\n",
    "    'facts_train' : n_facts_train, \n",
    "    'other_train' : n_other_train, \n",
    "    'facts_test' : n_facts_test, \n",
    "    'other_test' : n_other_test\n",
    "  }\n",
    "  dl_train = torch.utils.data.DataLoader(ds_train, batch_size=batch_size, shuffle=True)\n",
    "  dl_test = torch.utils.data.DataLoader(ds_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "  sentence_classifier = SentenceClassifier().to(device)\n",
    "  criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "  optimizer = torch.optim.Adam(\n",
    "    sentence_classifier.parameters(), \n",
    "    lr=learning_rate, \n",
    "    betas=(0.9, 0.999), \n",
    "    eps=1e-8, \n",
    "    weight_decay=weight_decay\n",
    "  )\n",
    "  lr_scheduler = transformers.get_linear_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps = 0, \n",
    "    num_training_steps = len(dl_train) * n_epochs\n",
    "  )\n",
    "  \n",
    "  metrics = {} # key: epoch number, value: numpy tensor storing train loss, test loss, Precision, Recall, F1\n",
    "  for epoch in range(1, n_epochs + 1):\n",
    "    epoch_loss = 0\n",
    "    sentence_classifier.train()\n",
    "    for train_data in tqdm(dl_train, desc=f'Epoch {epoch} (train)'):\n",
    "      optimizer.zero_grad()\n",
    "      ids = train_data['ids'].to(device)\n",
    "      mask = train_data['mask'].to(device)\n",
    "      token_type_ids = train_data['token_type_ids'].to(device)\n",
    "      pe = train_data['pe'].to(device)\n",
    "      y_hat = sentence_classifier(ids, mask, token_type_ids, pe)\n",
    "      y_true = train_data['target'].to(device)\n",
    "      loss = criterion(y_hat, y_true)\n",
    "      epoch_loss += loss.item()\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(sentence_classifier.parameters(), 1.0)\n",
    "      optimizer.step()\n",
    "      lr_scheduler.step()\n",
    "    epoch_loss = epoch_loss / len(dl_train)\n",
    "    # evaluation\n",
    "    optimizer.zero_grad()\n",
    "    eval_loss, p, r, f1 = evaluate(sentence_classifier, dl_test, criterion)\n",
    "    #storing metrics\n",
    "    metrics[epoch] = np.array([epoch_loss, eval_loss, p, r, f1])\n",
    "    print(f'=> Epoch {epoch}')\n",
    "    print(f'  Train loss: {epoch_loss:.6f}')\n",
    "    print(f'  Test loss:  {eval_loss:.6f}')\n",
    "    print(f'  Precision:  {p:.6f}')\n",
    "    print(f'  Recall:     {r:.6f}')\n",
    "    print(f'  F1:         {f1:.6f}')\n",
    "    time.sleep(0.5) # in order to don't mess the progress bars\n",
    "  \n",
    "  return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "rural-peripheral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************\n",
      "               FOLD 0\n",
      "********************************************\n",
      "Train dataset numbers:\n",
      " Total number of sentences: 7693\n",
      " Number of Facts labels: 1584\n",
      " Number of Other labels: 6109\n",
      "Test dataset numbers:\n",
      " Total number of sentences: 1687\n",
      " Number of Facts labels: 635\n",
      " Number of Other labels: 1052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Epoch 1 (train): 100%|██████████| 241/241 [03:19<00:00,  1.21it/s]\n",
      "Evaluation: 100%|██████████| 53/53 [00:12<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 1\n",
      "  Train loss: 0.415959\n",
      "  Test loss:  0.730664\n",
      "  Precision:  0.878788\n",
      "  Recall:     0.274016\n",
      "  F1:         0.417767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 (train): 100%|██████████| 241/241 [03:19<00:00,  1.21it/s]\n",
      "Evaluation: 100%|██████████| 53/53 [00:12<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 2\n",
      "  Train loss: 0.301840\n",
      "  Test loss:  0.485368\n",
      "  Precision:  0.758879\n",
      "  Recall:     0.639370\n",
      "  F1:         0.694017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 (train): 100%|██████████| 241/241 [03:19<00:00,  1.21it/s]\n",
      "Evaluation: 100%|██████████| 53/53 [00:12<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 3\n",
      "  Train loss: 0.228913\n",
      "  Test loss:  0.534734\n",
      "  Precision:  0.745027\n",
      "  Recall:     0.648819\n",
      "  F1:         0.693603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 (train): 100%|██████████| 241/241 [03:19<00:00,  1.21it/s]\n",
      "Evaluation: 100%|██████████| 53/53 [00:12<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 4\n",
      "  Train loss: 0.183557\n",
      "  Test loss:  0.649592\n",
      "  Precision:  0.732955\n",
      "  Recall:     0.609449\n",
      "  F1:         0.665520\n",
      "********************************************\n",
      "               FOLD 1\n",
      "********************************************\n",
      "Train dataset numbers:\n",
      " Total number of sentences: 7782\n",
      " Number of Facts labels: 1772\n",
      " Number of Other labels: 6010\n",
      "Test dataset numbers:\n",
      " Total number of sentences: 1598\n",
      " Number of Facts labels: 447\n",
      " Number of Other labels: 1151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Epoch 1 (train): 100%|██████████| 244/244 [02:48<00:00,  1.45it/s]\n",
      "Evaluation: 100%|██████████| 50/50 [00:14<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 1\n",
      "  Train loss: 0.501135\n",
      "  Test loss:  0.561656\n",
      "  Precision:  0.739437\n",
      "  Recall:     0.469799\n",
      "  F1:         0.574555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 (train): 100%|██████████| 244/244 [02:48<00:00,  1.45it/s]\n",
      "Evaluation: 100%|██████████| 50/50 [00:14<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 2\n",
      "  Train loss: 0.349783\n",
      "  Test loss:  0.481582\n",
      "  Precision:  0.716621\n",
      "  Recall:     0.588367\n",
      "  F1:         0.646192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 (train): 100%|██████████| 244/244 [02:48<00:00,  1.45it/s]\n",
      "Evaluation: 100%|██████████| 50/50 [00:14<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 3\n",
      "  Train loss: 0.270351\n",
      "  Test loss:  0.681710\n",
      "  Precision:  0.759398\n",
      "  Recall:     0.451902\n",
      "  F1:         0.566620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 (train): 100%|██████████| 244/244 [02:48<00:00,  1.45it/s]\n",
      "Evaluation: 100%|██████████| 50/50 [00:14<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 4\n",
      "  Train loss: 0.208616\n",
      "  Test loss:  0.685879\n",
      "  Precision:  0.729730\n",
      "  Recall:     0.483221\n",
      "  F1:         0.581427\n",
      "********************************************\n",
      "               FOLD 2\n",
      "********************************************\n",
      "Train dataset numbers:\n",
      " Total number of sentences: 7002\n",
      " Number of Facts labels: 1844\n",
      " Number of Other labels: 5158\n",
      "Test dataset numbers:\n",
      " Total number of sentences: 2378\n",
      " Number of Facts labels: 375\n",
      " Number of Other labels: 2003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Epoch 1 (train): 100%|██████████| 219/219 [03:01<00:00,  1.21it/s]\n",
      "Evaluation: 100%|██████████| 75/75 [00:16<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 1\n",
      "  Train loss: 0.590187\n",
      "  Test loss:  0.355810\n",
      "  Precision:  0.580071\n",
      "  Recall:     0.434667\n",
      "  F1:         0.496951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 (train): 100%|██████████| 219/219 [03:01<00:00,  1.21it/s]\n",
      "Evaluation: 100%|██████████| 75/75 [00:16<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 2\n",
      "  Train loss: 0.416358\n",
      "  Test loss:  0.361636\n",
      "  Precision:  0.567123\n",
      "  Recall:     0.552000\n",
      "  F1:         0.559459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 (train): 100%|██████████| 219/219 [03:01<00:00,  1.21it/s]\n",
      "Evaluation: 100%|██████████| 75/75 [00:16<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 3\n",
      "  Train loss: 0.317612\n",
      "  Test loss:  0.380199\n",
      "  Precision:  0.575843\n",
      "  Recall:     0.546667\n",
      "  F1:         0.560876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 (train): 100%|██████████| 219/219 [03:01<00:00,  1.21it/s]\n",
      "Evaluation: 100%|██████████| 75/75 [00:16<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 4\n",
      "  Train loss: 0.247916\n",
      "  Test loss:  0.423867\n",
      "  Precision:  0.550369\n",
      "  Recall:     0.597333\n",
      "  F1:         0.572890\n",
      "********************************************\n",
      "               FOLD 3\n",
      "********************************************\n",
      "Train dataset numbers:\n",
      " Total number of sentences: 7581\n",
      " Number of Facts labels: 1863\n",
      " Number of Other labels: 5718\n",
      "Test dataset numbers:\n",
      " Total number of sentences: 1799\n",
      " Number of Facts labels: 356\n",
      " Number of Other labels: 1443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Epoch 1 (train): 100%|██████████| 237/237 [03:16<00:00,  1.20it/s]\n",
      "Evaluation: 100%|██████████| 57/57 [00:12<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 1\n",
      "  Train loss: 0.481942\n",
      "  Test loss:  0.325161\n",
      "  Precision:  0.692308\n",
      "  Recall:     0.556180\n",
      "  F1:         0.616822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 (train): 100%|██████████| 237/237 [03:16<00:00,  1.20it/s]\n",
      "Evaluation: 100%|██████████| 57/57 [00:12<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 2\n",
      "  Train loss: 0.353289\n",
      "  Test loss:  0.400022\n",
      "  Precision:  0.540490\n",
      "  Recall:     0.806180\n",
      "  F1:         0.647125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 (train): 100%|██████████| 237/237 [03:16<00:00,  1.20it/s]\n",
      "Evaluation: 100%|██████████| 57/57 [00:12<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 3\n",
      "  Train loss: 0.275034\n",
      "  Test loss:  0.403940\n",
      "  Precision:  0.550980\n",
      "  Recall:     0.789326\n",
      "  F1:         0.648961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 (train): 100%|██████████| 237/237 [03:16<00:00,  1.20it/s]\n",
      "Evaluation: 100%|██████████| 57/57 [00:12<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 4\n",
      "  Train loss: 0.211402\n",
      "  Test loss:  0.440946\n",
      "  Precision:  0.548729\n",
      "  Recall:     0.727528\n",
      "  F1:         0.625604\n",
      "********************************************\n",
      "               FOLD 4\n",
      "********************************************\n",
      "Train dataset numbers:\n",
      " Total number of sentences: 7462\n",
      " Number of Facts labels: 1813\n",
      " Number of Other labels: 5649\n",
      "Test dataset numbers:\n",
      " Total number of sentences: 1918\n",
      " Number of Facts labels: 406\n",
      " Number of Other labels: 1512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Epoch 1 (train): 100%|██████████| 234/234 [03:13<00:00,  1.21it/s]\n",
      "Evaluation: 100%|██████████| 60/60 [00:10<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 1\n",
      "  Train loss: 0.634917\n",
      "  Test loss:  0.403533\n",
      "  Precision:  0.597619\n",
      "  Recall:     0.618227\n",
      "  F1:         0.607748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 (train): 100%|██████████| 234/234 [03:13<00:00,  1.21it/s]\n",
      "Evaluation: 100%|██████████| 60/60 [00:10<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 2\n",
      "  Train loss: 0.431159\n",
      "  Test loss:  0.386178\n",
      "  Precision:  0.587196\n",
      "  Recall:     0.655172\n",
      "  F1:         0.619325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 (train): 100%|██████████| 234/234 [03:13<00:00,  1.21it/s]\n",
      "Evaluation: 100%|██████████| 60/60 [00:10<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 3\n",
      "  Train loss: 0.326162\n",
      "  Test loss:  0.417306\n",
      "  Precision:  0.568627\n",
      "  Recall:     0.714286\n",
      "  F1:         0.633188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 (train): 100%|██████████| 234/234 [03:13<00:00,  1.21it/s]\n",
      "Evaluation: 100%|██████████| 60/60 [00:10<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch 4\n",
      "  Train loss: 0.251302\n",
      "  Test loss:  0.462850\n",
      "  Precision:  0.565762\n",
      "  Recall:     0.667488\n",
      "  F1:         0.612429\n",
      "CPU times: user 50min 40s, sys: 16min 41s, total: 1h 7min 22s\n",
      "Wall time: 1h 7min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training params\n",
    "n_epochs = 4\n",
    "learning_rate = 2e-5\n",
    "weight_decay = 1e-3\n",
    "batch_size = 32\n",
    "\n",
    "#fold_ids = [0, 1] # for code validation\n",
    "raw_metrics = {} # key: epoch, value: numpy tensor of shape (n_folds, 5)\n",
    "for fold_id in fold_ids:\n",
    "  print('********************************************')\n",
    "  print(f'               FOLD {fold_id}')\n",
    "  print('********************************************')\n",
    "  fold_metrics = train(fold_id, learning_rate, weight_decay, n_epochs, batch_size)\n",
    "  for epoch, scores in fold_metrics.items():\n",
    "    epoch_metrics = raw_metrics.get(epoch, None)\n",
    "    if epoch_metrics is None:\n",
    "      raw_metrics[epoch] = scores\n",
    "    else:\n",
    "      raw_metrics[epoch] = np.vstack((epoch_metrics, scores))\n",
    "\n",
    "metrics = pd.DataFrame(columns=['Epoch', 'Train loss', 'std', 'Test loss', 'std', 'Precision', 'P std', 'Recall', 'R std', 'F1', 'F1 std'])\n",
    "for i, (epoch, scores) in enumerate(raw_metrics.items()):\n",
    "  mean = np.mean(scores, axis=0)\n",
    "  std = np.std(scores, axis=0)\n",
    "  metrics.loc[i] = [\n",
    "      f'{epoch}', \n",
    "      f'{mean[0]:.6f}', f'{std[0]:.6f}',  # train loss\n",
    "      f'{mean[1]:.6f}', f'{std[1]:.6f}',  # test loss\n",
    "      f'{mean[2]:.4f}', f'{std[2]:.4f}',  # precision\n",
    "      f'{mean[3]:.4f}', f'{std[3]:.4f}',  # recall\n",
    "      f'{mean[4]:.4f}', f'{std[4]:.4f}'   # f1\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-trial",
   "metadata": {},
   "source": [
    "### Outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "impressed-authentication",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def save_report(avg_metrics, complete_metrics, dest_dir):\n",
    "  \"\"\"\n",
    "  Arguments:\n",
    "    avg_metrics : A pandas Dataframe with the averaged metrics.\n",
    "    complete_metrics : A dictionary with the metrics by epoch. The key indicates the epoch. \n",
    "              Each value must be a numpy tensor of shape (n_folds, 5).\n",
    "    dest_dir : The directory where the report will be saved.\n",
    "  \"\"\"\n",
    "  report = (\n",
    "      'RESULTS REPORT\\n'\n",
    "      'Model: Legal BERT\\n'\n",
    "      'Evaluation: cross-validation\\n'\n",
    "      'Train scheme: fine-tuning\\n'\n",
    "      f'Batch size: {batch_size}\\n'\n",
    "      f'Learning rate: {learning_rate}\\n'\n",
    "      f'Weight decay: {weight_decay}\\n\\n'\n",
    "  )\n",
    "  \n",
    "  report += 'Averages:\\n'\n",
    "  report += avg_metrics.to_string(index=False, justify='center')\n",
    "  \n",
    "  report += '\\n\\nDetailed report:\\n'\n",
    "  report += 'Supports by fold:\\n'\n",
    "  for fold_id, support in supports_by_fold.items():\n",
    "    report += f'=> Fold {fold_id}:\\n'\n",
    "    report += f'  Facts (train): {support[\"facts_train\"]}\\t\\tOther (train): {support[\"other_train\"]}\\n'\n",
    "    report += f'  Facts (test): {support[\"facts_test\"]}\\t\\tOther (test): {support[\"other_test\"]}\\n'\n",
    "  \n",
    "  report += '\\nScores:\\n'\n",
    "  for epoch, scores in complete_metrics.items():\n",
    "    df = pd.DataFrame(\n",
    "      scores, \n",
    "      columns=['Train loss', 'Test loss', 'Precision', 'Recall', 'F1'], \n",
    "      index=[f'Fold {i}' for i in range(scores.shape[0])])\n",
    "    report += f'Epoch: {epoch}\\n' + df.to_string() + '\\n\\n'\n",
    "    \n",
    "  with open(dest_dir + f'report-{model_reference}_ft_{datetime.now().strftime(\"%Y-%m-%d-%Hh%Mmin\")}.txt', 'w') as f:\n",
    "    f.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "champion-novelty",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_report(metrics, raw_metrics, './')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "qualified-edgar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Train loss</th>\n",
       "      <th>std</th>\n",
       "      <th>Test loss</th>\n",
       "      <th>std</th>\n",
       "      <th>Precision</th>\n",
       "      <th>P std</th>\n",
       "      <th>Recall</th>\n",
       "      <th>R std</th>\n",
       "      <th>F1</th>\n",
       "      <th>F1 std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.524828</td>\n",
       "      <td>0.078287</td>\n",
       "      <td>0.475365</td>\n",
       "      <td>0.151419</td>\n",
       "      <td>0.6976</td>\n",
       "      <td>0.1081</td>\n",
       "      <td>0.4706</td>\n",
       "      <td>0.1175</td>\n",
       "      <td>0.5428</td>\n",
       "      <td>0.0754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.370486</td>\n",
       "      <td>0.047375</td>\n",
       "      <td>0.422957</td>\n",
       "      <td>0.050933</td>\n",
       "      <td>0.6341</td>\n",
       "      <td>0.0870</td>\n",
       "      <td>0.6482</td>\n",
       "      <td>0.0871</td>\n",
       "      <td>0.6332</td>\n",
       "      <td>0.0440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.283614</td>\n",
       "      <td>0.035236</td>\n",
       "      <td>0.483578</td>\n",
       "      <td>0.112512</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.0921</td>\n",
       "      <td>0.6302</td>\n",
       "      <td>0.1196</td>\n",
       "      <td>0.6206</td>\n",
       "      <td>0.0505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.220559</td>\n",
       "      <td>0.025648</td>\n",
       "      <td>0.532627</td>\n",
       "      <td>0.111597</td>\n",
       "      <td>0.6255</td>\n",
       "      <td>0.0866</td>\n",
       "      <td>0.6170</td>\n",
       "      <td>0.0814</td>\n",
       "      <td>0.6116</td>\n",
       "      <td>0.0332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Epoch Train loss       std Test loss       std Precision   P std  Recall  \\\n",
       "0     1   0.524828  0.078287  0.475365  0.151419    0.6976  0.1081  0.4706   \n",
       "1     2   0.370486  0.047375  0.422957  0.050933    0.6341  0.0870  0.6482   \n",
       "2     3   0.283614  0.035236  0.483578  0.112512    0.6400  0.0921  0.6302   \n",
       "3     4   0.220559  0.025648  0.532627  0.111597    0.6255  0.0866  0.6170   \n",
       "\n",
       "    R std      F1  F1 std  \n",
       "0  0.1175  0.5428  0.0754  \n",
       "1  0.0871  0.6332  0.0440  \n",
       "2  0.1196  0.6206  0.0505  \n",
       "3  0.0814  0.6116  0.0332  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "metrics_display = display(metrics, display_id='metrics_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-pension",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
