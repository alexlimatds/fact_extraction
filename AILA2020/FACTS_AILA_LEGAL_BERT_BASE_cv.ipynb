{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FACTS_AILA_LEGAL-BERT-BASE_cv.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPlH/9yxZpCV0c6IAinqyNg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexlimatds/fact_extraction/blob/main/AILA2020/FACTS_AILA_LEGAL_BERT_BASE_cv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Facts extraction with AILA data and LEGAL-BERT-BASE\n",
        "\n",
        "The model is evaluated through a cross-validation but this notebook doesn't perform the hole cross-validation process. Instead, it runs just one fold of the cross-validation. The fold to be used is indicated by the ``fold_id`` variable.\n",
        "\n",
        "We use the train dataset from AILA 2020. This can be obtained at https://github.com/Law-AI/semantic-segmentation;\n",
        "\n",
        "LEGAL-BERT is available at https://huggingface.co/nlpaueb/legal-bert-base-uncased.\n",
        "\n",
        "https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_multiclass_classification.ipynb"
      ],
      "metadata": {
        "id": "ohzP-teEOWXb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Notebook parameters"
      ],
      "metadata": {
        "id": "6DhVLzBnM3dS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = 'nlpaueb/legal-bert-base-uncased'\n",
        "model_reference = 'legal-bert-base'\n",
        "fold_id = 0"
      ],
      "metadata": {
        "id": "3Hy_f0znM34X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dependencies"
      ],
      "metadata": {
        "id": "IUhTTnV4R8jV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "w3YH2lz9YnrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "transformers.__version__"
      ],
      "metadata": {
        "id": "Iom58i1kVbpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "metadata": {
        "id": "hzAZlqnbV9BU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "sklearn.__version__"
      ],
      "metadata": {
        "id": "MrBSXH0MWBr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.__version__"
      ],
      "metadata": {
        "id": "_cfPI7nvWJlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading dataset"
      ],
      "metadata": {
        "id": "yil5cleMPIJg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCMDWIy4OSSA"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "g_drive_dir = '/content/gdrive/MyDrive/'\n",
        "dataset_dir = 'fact_extraction_AILA/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r data\n",
        "!mkdir data\n",
        "!mkdir data/train\n",
        "!tar -xf {g_drive_dir}{dataset_dir}/train.tar.xz -C data/train\n",
        "\n",
        "train_dir = 'data/train/'"
      ],
      "metadata": {
        "id": "dmeH4B-EPOyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "def read_docs(dir_name):\n",
        "  \"\"\"\n",
        "  Read the docs in a directory.\n",
        "  Params:\n",
        "    dir_name : the directory that contains the documents.\n",
        "  Returns:\n",
        "    A dictionary whose keys are the names of the read files and the values are \n",
        "    pandas dataframes. Each dataframe has sentence and label columns.\n",
        "  \"\"\"\n",
        "  docs = {} # key: file name, value: dataframe with sentences and labels\n",
        "  for f in listdir(dir_name):\n",
        "    df = pd.read_csv(\n",
        "        dir_name + f, \n",
        "        sep='\\t', \n",
        "        quoting=csv.QUOTE_NONE, \n",
        "        names=['sentence', 'label'])\n",
        "    docs[f] = df\n",
        "  return docs\n",
        "\n",
        "docs_dic = read_docs(train_dir)\n",
        "\n",
        "print('Number of documents: ', len(docs_dic))"
      ],
      "metadata": {
        "id": "JCKmMvOPPjqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizer and Dataset preparation"
      ],
      "metadata": {
        "id": "GB1x8075PPsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "IInanTkqKlnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self, sentences, labels, tokenizer):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "      sentences : list of strings.\n",
        "      lables : list of strings.\n",
        "    \"\"\"\n",
        "    self.len = len(sentences)\n",
        "    self.targets = []\n",
        "    for l in labels:\n",
        "      if l == 'Facts':\n",
        "        self.targets.append(1.0)\n",
        "      elif l == 'Other':\n",
        "        self.targets.append(0.0)\n",
        "      else:\n",
        "        raise ValueError('Unknown label: ', l)\n",
        "    self.targets = torch.tensor(self.targets, dtype=torch.float)\n",
        "    self.data = tokenizer(\n",
        "      sentences, \n",
        "      None,\n",
        "      add_special_tokens=True,\n",
        "      padding='longest', \n",
        "      return_token_type_ids=True,\n",
        "      truncation=True, \n",
        "      return_tensors='pt'\n",
        "    )\n",
        "    self.data['input_ids'].to(device)\n",
        "    self.data['attention_mask'].to(device)\n",
        "    self.targets.to(device)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return {\n",
        "      'ids': self.data['input_ids'][index],\n",
        "      'mask': self.data['attention_mask'][index],\n",
        "      'targets': self.targets[index]\n",
        "    }\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.len\n"
      ],
      "metadata": {
        "id": "-DGyjLC_iWqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_folds = pd.read_csv(\n",
        "  g_drive_dir + dataset_dir + 'train_docs_by_fold.csv', \n",
        "  sep=';', \n",
        "  names=['fold id', 'train', 'test'], \n",
        "  header=0)\n",
        "\n",
        "for _, row in df_folds.iterrows():\n",
        "  if row['fold id'] == fold_id:\n",
        "    train_files = row['train'].split(',')\n",
        "    test_files = row['test'].split(',')\n",
        "\n",
        "print('Train documents: ', train_files)\n",
        "print('Test documents: ', test_files)"
      ],
      "metadata": {
        "id": "xE-aSMif1aOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset(docs_list):\n",
        "  sentences = []\n",
        "  labels = []\n",
        "  for doc_id in docs_list:\n",
        "    sentences.extend(docs_dic[doc_id]['sentence'].to_list())\n",
        "    labels.extend(docs_dic[doc_id]['label'].to_list())\n",
        "  #return MyDataset(sentences[:11], labels[:11], tokenizer) # for code validation\n",
        "  return MyDataset(sentences, labels, tokenizer)\n",
        "\n",
        "ds_train = get_dataset(train_files)\n",
        "ds_test = get_dataset(test_files)"
      ],
      "metadata": {
        "id": "09uDF8ql449C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "WldJnkLpFica"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SentenceClassifier(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SentenceClassifier, self).__init__()\n",
        "    self.mlp_hidden_dim = 100\n",
        "    self.bert = transformers.AutoModel.from_pretrained(model_id)\n",
        "    self.pre_classifier = torch.nn.Linear(768, self.mlp_hidden_dim) # 768 is the embedding dimension of BERT's hidden layers\n",
        "    self.dropout = torch.nn.Dropout(0.3)\n",
        "    self.classifier = torch.nn.Linear(self.mlp_hidden_dim, 1)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    # input_ids.shape: (batch_size, seq_len)\n",
        "    # attention_mask.shape: (batch_size, seq_len)\n",
        "    output_1 = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    hidden_state = output_1[0]    # hidden states of last BERT's layer => shape: (batch_size, seq_len, embedd_dim)\n",
        "    pooler = hidden_state[:, 0]   # hidden state of the CLS token => shape: (batch_size, embedd_dim)\n",
        "    pooler = self.pre_classifier(pooler)  # shape: (batch_size, mlp_hidden_dim)\n",
        "    pooler = torch.nn.ReLU()(pooler)      # shape: (batch_size, mlp_hidden_dim)\n",
        "    pooler = self.dropout(pooler)         # shape: (batch_size, mlp_hidden_dim)\n",
        "    output = self.classifier(pooler)      # shape: (batch_size, 1)\n",
        "    return output\n",
        "\n",
        "  def predict(self, input_ids, attention_mask):\n",
        "    self.eval()\n",
        "    output = self.forward(input_ids, attention_mask).squeeze()\n",
        "    output[output >= 0] = 1\n",
        "    output[output < 0] = 0\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "Qun096CwFkO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "f7ze6Wpl_3Tz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "\n",
        "test_metrics = {}\n",
        "\n",
        "def evaluate(model, epoch, test_dataloader):\n",
        "  predictions = None\n",
        "  y_true = None\n",
        "  #for data in test_dataloader:\n",
        "  for data in tqdm_notebook(test_dataloader, desc='Evaluation'):\n",
        "    y_hat = model.predict(data['ids'], data['mask'])\n",
        "    if predictions is None:\n",
        "      predictions = y_hat\n",
        "      y_true = data['targets']\n",
        "    else:\n",
        "      predictions = torch.concat((predictions, y_hat))\n",
        "      y_true = torch.concat((y_true, data['targets']))\n",
        "\n",
        "  predictions = predictions.detach().to('cpu').numpy()\n",
        "  y_true = y_true.detach().to('cpu').numpy()  \n",
        "  # Precision, Recall, F1\n",
        "  t_metrics = precision_recall_fscore_support(\n",
        "    y_true, \n",
        "    predictions, \n",
        "    average='binary', \n",
        "    pos_label=1, \n",
        "    zero_division=0)\n",
        "  print(f'Precision: {t_metrics[0]:.4f}')\n",
        "  print(f'Recall:    {t_metrics[1]:.4f}')\n",
        "  print(f'F-score:   {t_metrics[2]:.4f}')\n",
        "  test_metrics[epoch] = {\n",
        "      'precision': t_metrics[0], \n",
        "      'recall': t_metrics[1], \n",
        "      'f1': t_metrics[2]\n",
        "  }"
      ],
      "metadata": {
        "id": "kn7cqkI2JxJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def save_report(fold_id, metrics, dest_dir):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "    fold_id : The identifier of the cross-validation fold.\n",
        "    metrics : A dictionary with the metrics by epoch. The key indicates the epoch. \n",
        "              Each value must be a dictionary.\n",
        "    dest_dir : The directory where the report will be saved.\n",
        "  \"\"\"\n",
        "  report = 'OBS: the zero epoch concerns to the model\\'s performance before any fine-tuning step.\\n\\n'\n",
        "  report += 'epoch\\t Precision   Recall   F1\\n------------------------------------\\n'\n",
        "  for i in range(len(metrics)):\n",
        "    dic = metrics[i]\n",
        "    report += f'{i}\\t {dic[\"precision\"]:.4f}      {dic[\"recall\"]:.4f}   {dic[\"f1\"]:.4f}\\n'\n",
        "  \n",
        "  with open(dest_dir + f'report-{model_reference}_fold-{fold_id}_{datetime.now().strftime(\"%Y-%m-%d\")}.txt', 'w') as f:\n",
        "    f.write(report)"
      ],
      "metadata": {
        "id": "2pnuclWF45qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-tuning"
      ],
      "metadata": {
        "id": "2BbHhPlsNnr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "sentence_classifier = SentenceClassifier()"
      ],
      "metadata": {
        "id": "nIHuw7dBNokg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dl_train = torch.utils.data.DataLoader(ds_train, batch_size=8)\n",
        "dl_test = torch.utils.data.DataLoader(ds_test, batch_size=8)"
      ],
      "metadata": {
        "id": "b51w9A7DAwbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# evaluating model before fine-tunning\n",
        "evaluate(sentence_classifier, 0, dl_test)"
      ],
      "metadata": {
        "id": "sVzej6WTCg3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Training params\n",
        "n_epochs = 5\n",
        "learning_rate = 5e-5\n",
        "\n",
        "criterion = torch.nn.BCEWithLogitsLoss().to(device)\n",
        "sentence_classifier.to(device)\n",
        "optimizer = torch.optim.Adam(\n",
        "  sentence_classifier.parameters(), \n",
        "  lr=learning_rate\n",
        ")\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  print(f'*** Epoch {epoch} ***')\n",
        "  for train_data in tqdm_notebook(dl_train, desc=f'Epoch {epoch}'):\n",
        "    # training\n",
        "    sentence_classifier.train()\n",
        "    optimizer.zero_grad()\n",
        "    y_hat = sentence_classifier(train_data['ids'], train_data['mask'])\n",
        "    loss = criterion(y_hat.squeeze(), train_data['targets'])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  # evaluation\n",
        "  evaluate(sentence_classifier, epoch, dl_test)\n"
      ],
      "metadata": {
        "id": "9s7aSi4Wf41Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_report(fold_id, test_metrics, g_drive_dir + dataset_dir)"
      ],
      "metadata": {
        "id": "kqsdTUtS9e-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Outline"
      ],
      "metadata": {
        "id": "aEhLWhTdqpBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "\n",
        "metrics_df = pd.DataFrame(columns=['Epoch', 'Precision', 'Recall', 'F1'])\n",
        "for epoch in range(len(test_metrics)):\n",
        "  metrics = test_metrics[epoch]\n",
        "  metrics_df.loc[epoch] = [epoch, f'{metrics[\"precision\"]:.4f}', f'{metrics[\"recall\"]:.4f}', f'{metrics[\"f1\"]:.4f}']\n",
        "display(HTML(f'<br><span style=\"font-weight: bold\">Test metrics: fold {fold_id}</span>'))\n",
        "metrics_display = display(metrics_df, display_id='metrics_table')"
      ],
      "metadata": {
        "id": "8ahklX-JHxAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### References\n",
        "\n",
        "- I. Chalkidis, M. Fergadiotis, P. Malakasiotis, N. Aletras and I. Androutsopoulos. **\"LEGAL-BERT: The Muppets straight out of Law School\"**. In Findings of Empirical Methods in Natural Language Processing (EMNLP 2020) (Short Papers), to be held online, 2020. (https://aclanthology.org/2020.findings-emnlp.261)\n",
        "- Paheli Bhattacharya, Shounak Paul, Kripabandhu Ghosh, Saptarshi Ghosh, and Adam Wyner. 2019. **Identification of Rhetorical Roles of Sentences in Indian Legal Judgments**. In Proc. International Conference on Legal Knowledge and Information Systems (JURIX)."
      ],
      "metadata": {
        "id": "YPd7d83W26x4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4DknAJdu2scx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}